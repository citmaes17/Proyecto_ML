{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8c4dd6",
   "metadata": {},
   "source": [
    "# 0. Split inicial del dataset (enfoque purista)\n",
    "\n",
    "En este notebook se realiza el **split inicial** del dataset original en dos partes:\n",
    "\n",
    "- `train_master.csv` → 80% de los datos, que se usará para EDA, CDA, segmentación y modelado.\n",
    "- `test_master.csv` → 20% de los datos, que se reservará para la **evaluación final** del modelo.\n",
    "\n",
    "⚠️ **Importante:** aquí todavía **no existen** las variables de churn ni CLV; el split se hace sobre el dataset crudo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c1d9f",
   "metadata": {},
   "source": [
    "## 1. Cargar dataset original\n",
    "\n",
    "Cargamos el archivo original `superstore_data.csv` desde la carpeta `data/`. En tu proyecto local, este notebook debería estar en la carpeta `notebooks/`, por lo que la ruta relativa será `../data/superstore_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4760ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data/superstore_data.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b759c",
   "metadata": {},
   "source": [
    "## 2. División en train y test\n",
    "\n",
    "Usamos `train_test_split` para dividir el dataset en dos subconjuntos:\n",
    "\n",
    "- `train_master` (80%)\n",
    "- `test_master` (20%)\n",
    "\n",
    "Si en tu dataset original ya existiera alguna columna de etiqueta, podrías usar `stratify` para mantener las proporciones; si no, se hace un split simple aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_df.shape, test_df.shape\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aaf019",
   "metadata": {},
   "source": [
    "## 3. Guardar `train_master.csv` y `test_master.csv`\n",
    "\n",
    "Guardamos ambos subconjuntos en la carpeta `data/` para que el resto de notebooks los usen:\n",
    "\n",
    "- `1_EDA_Superstore.ipynb` trabajará con `train_master.csv`.\n",
    "- `5_Evaluacion_TestMaster.ipynb` usará `test_master.csv` para la evaluación final del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ccf972",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"output_path = Path(\"../data\")\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "train_df.to_csv(output_path / \"train_master.csv\", index=False)\n",
    "test_df.to_csv(output_path / \"test_master.csv\", index=False)\n",
    "\n",
    "print(\"train_master.csv y test_master.csv guardados en:\", output_path)\n",
    "\"\"\"\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
