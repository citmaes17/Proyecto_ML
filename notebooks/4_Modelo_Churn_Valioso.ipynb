{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999c95d4",
   "metadata": {},
   "source": [
    "\n",
    "# 4️⃣ Modelo Supervisado de **Churn Valioso K-Means**\n",
    "\n",
    "En este notebook vamos a construir un **modelo supervisado** para predecir la probabilidad de que un cliente pertenezca a la clase **`Churn_Valioso_KMeans = 1`**.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Cargar el dataset procesado (`superstore_procesado.csv`) y **crear/revisar** la variable objetivo de churn valioso.\n",
    "2. Definir el conjunto de variables (features) para el modelo de churn valioso.\n",
    "3. Preparar un **pipeline de preprocesamiento** (imputación, escalado, one-hot encoding).\n",
    "4. Entrenar y comparar dos modelos:\n",
    "   - **Regresión logística** (con regularización L1 / L2).\n",
    "   - **Random Forest**.\n",
    "5. Usar **GridSearchCV** con validación cruzada estratificada y métrica **ROC-AUC**.\n",
    "6. Evaluar el mejor modelo en un conjunto de validación (hold-out).\n",
    "7. Analizar la **importancia de variables** (coeficientes o feature importances).\n",
    "8. Guardar el pipeline completo entrenado en `../models/churn_pipeline.pkl`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea5683",
   "metadata": {},
   "source": [
    "## 1. Carga de datos y creación de la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b26d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuración visual\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set(font_scale=1.0)\n",
    "\n",
    "data_path = Path(\"../data/superstore_procesado.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Columnas del dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea97d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Definición de Churn Valioso K-Means (por si NO viene ya en el CSV) ---\n",
    "# Definición tomada del notebook de CDA:\n",
    "# - Inactivo: Recency >= 83 (umbral del cluster más inactivo en K-Means)\n",
    "# - Valioso: CLV_log >= mediana\n",
    "# - Churn_Valioso_KMeans = 1 si se cumplen ambas condiciones\n",
    "\n",
    "UMBRAL_RECENCY_KMEANS = 83\n",
    "\n",
    "if \"Churn_Valioso_KMeans\" not in df.columns:\n",
    "    if \"CLV_log\" not in df.columns:\n",
    "        # Si por alguna razón no existe CLV_log, lo recalculamos\n",
    "        df[\"CLV_log\"] = np.log1p(df[\"MntTotal\"]) * np.log1p(df[\"TotalPurchases\"])\n",
    "    \n",
    "    mediana_clv = df[\"CLV_log\"].median()\n",
    "\n",
    "    df[\"Churn_Valioso_KMeans\"] = (\n",
    "        (df[\"Recency\"] >= UMBRAL_RECENCY_KMEANS) &\n",
    "        (df[\"CLV_log\"] >= mediana_clv)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Opcional: churn simple solo por recency, útil para análisis comparativo\n",
    "    df[\"Churn_KMeans\"] = (df[\"Recency\"] >= UMBRAL_RECENCY_KMEANS).astype(int)\n",
    "\n",
    "    print(\"✅ Columnas de churn creadas desde la definición original de CDA.\")\n",
    "else:\n",
    "    print(\"✅ Columnas de churn ya presentes en el dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b190e6",
   "metadata": {},
   "source": [
    "## 2. Distribución de la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_col = \"Churn_Valioso_KMeans\"\n",
    "\n",
    "tasa_churn = (df[target_col].value_counts(normalize=True).round(4) * 100)\n",
    "print(\"Distribución de Churn_Valioso_KMeans (%):\")\n",
    "print(tasa_churn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4e008",
   "metadata": {},
   "source": [
    "\n",
    "La celda anterior muestra el **porcentaje de clientes churn valioso (1)** frente a **no churn valioso (0)**.\n",
    "Normalmente, el churn valioso será un porcentaje pequeño del total de clientes, lo que implica un:\n",
    "\n",
    "> **Problema de clases desbalanceadas** → hay muchos más ejemplos de clase 0 que de clase 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gráfico de barras de la distribución de la clase\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.barplot(\n",
    "    x=tasa_churn.index.astype(str),\n",
    "    y=tasa_churn.values,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"Distribución de Churn Valioso K-Means\")\n",
    "ax.set_xlabel(\"Churn_Valioso_KMeans\")\n",
    "ax.set_ylabel(\"% de clientes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157df3fb",
   "metadata": {},
   "source": [
    "## 3. Selección de variables (features) y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features seleccionadas para el modelo supervisado\n",
    "feature_cols = [\n",
    "    \"Recency\", \"MntTotal\", \"TotalPurchases\", \"Income\",\n",
    "    \"Perc_CatalogPurchases\", \"NumWebVisitsMonth\",\n",
    "    \"Kidhome\", \"Teenhome\",\n",
    "    \"Education\", \"Marital_Status\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa215ae",
   "metadata": {},
   "source": [
    "\n",
    "**Nota:** No incluimos `CLV_log` como feature porque forma parte directa de la definición de churn valioso\n",
    "y generaría **data leakage**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3f787",
   "metadata": {},
   "source": [
    "## 4. Split train / validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4855978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698926d",
   "metadata": {},
   "source": [
    "\n",
    "Usamos un 80% de los datos para entrenamiento y 20% para validación, estratificando por la variable objetivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4cca6",
   "metadata": {},
   "source": [
    "## 5. Pipeline de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7094bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features = [\n",
    "    \"Recency\", \"MntTotal\", \"TotalPurchases\", \"Income\",\n",
    "    \"Perc_CatalogPurchases\", \"NumWebVisitsMonth\",\n",
    "    \"Kidhome\", \"Teenhome\"\n",
    "]\n",
    "categorical_features = [\"Education\", \"Marital_Status\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0834376",
   "metadata": {},
   "source": [
    "## 6. Modelos candidatos y GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "base_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"model\": [LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"liblinear\")],\n",
    "        \"model__penalty\": [\"l1\", \"l2\"],\n",
    "        \"model__C\": [0.1, 1.0, 10.0],\n",
    "    },\n",
    "    {\n",
    "        \"model\": [RandomForestClassifier(class_weight=\"balanced\", random_state=42)],\n",
    "        \"model__n_estimators\": [100, 300],\n",
    "        \"model__max_depth\": [None, 5, 10],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Modelos que se probarán en GridSearch:\")\n",
    "for params in param_grid:\n",
    "    for m in params[\"model\"]:\n",
    "        print(\" -\", type(m).__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938378b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=base_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a6aa6",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento y selección del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ed3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "best_model_name = type(best_model.named_steps[\"model\"]).__name__\n",
    "print(\"\\nMejor modelo seleccionado:\", best_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddd623",
   "metadata": {},
   "source": [
    "## 8. Evaluación en el conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ea416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, RocCurveDisplay\n",
    "\n",
    "y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "roc = roc_auc_score(y_val, y_val_proba)\n",
    "print(f\"ROC-AUC (validación): {roc:.4f}\\n\")\n",
    "\n",
    "print(\"Matriz de confusión (validación):\")\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nReporte de clasificación (validación):\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "RocCurveDisplay.from_predictions(y_val, y_val_proba, ax=ax)\n",
    "ax.set_title(\"Curva ROC - Validación\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ce22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\n",
    "ax.set_xlabel(\"Predicción\")\n",
    "ax.set_ylabel(\"Real\")\n",
    "ax.set_title(\"Matriz de confusión - Validación\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36089c03",
   "metadata": {},
   "source": [
    "## 9. Importancia de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db575fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohe = best_model.named_steps[\"preprocess\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "num_features = numeric_features\n",
    "cat_features = list(ohe.get_feature_names_out(categorical_features))\n",
    "all_features = num_features + cat_features\n",
    "\n",
    "best_model_name = type(best_model.named_steps[\"model\"]).__name__\n",
    "print(\"Mejor modelo:\", best_model_name)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if best_model_name == \"LogisticRegression\":\n",
    "    model = best_model.named_steps[\"model\"]\n",
    "    coef = model.coef_[0]\n",
    "    feat_imp = pd.DataFrame({\n",
    "        \"feature\": all_features,\n",
    "        \"importance\": coef\n",
    "    })\n",
    "    feat_imp[\"abs_importance\"] = feat_imp[\"importance\"].abs()\n",
    "    feat_imp = feat_imp.sort_values(\"abs_importance\", ascending=False).head(20)\n",
    "    \n",
    "    print(\"\\nTop 20 coeficientes (LogisticRegression):\")\n",
    "    print(feat_imp[[\"feature\", \"importance\"]])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    sns.barplot(data=feat_imp, x=\"abs_importance\", y=\"feature\", ax=ax)\n",
    "    ax.set_title(\"Importancia de variables (|coeficientes|)\")\n",
    "    ax.set_xlabel(\"|Coeficiente|\")\n",
    "    ax.set_ylabel(\"Feature\")\n",
    "    plt.show()\n",
    "\n",
    "elif best_model_name == \"RandomForestClassifier\":\n",
    "    model = best_model.named_steps[\"model\"]\n",
    "    importances = model.feature_importances_\n",
    "    feat_imp = pd.DataFrame({\n",
    "        \"feature\": all_features,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(\"importance\", ascending=False).head(20)\n",
    "    \n",
    "    print(\"\\nTop 20 importancias (RandomForest):\")\n",
    "    print(feat_imp)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    sns.barplot(data=feat_imp, x=\"importance\", y=\"feature\", ax=ax)\n",
    "    ax.set_title(\"Importancia de variables (Random Forest)\")\n",
    "    ax.set_xlabel(\"Importancia\")\n",
    "    ax.set_ylabel(\"Feature\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04056805",
   "metadata": {},
   "source": [
    "## 10. Guardado del pipeline entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00dbc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "models_path = Path(\"../models\")\n",
    "models_path.mkdir(exist_ok=True)\n",
    "\n",
    "model_path = models_path / \"churn_pipeline.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"✅ Modelo guardado en: {model_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}