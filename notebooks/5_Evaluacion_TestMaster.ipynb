{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd353fd",
   "metadata": {},
   "source": [
    "# 5. Evaluación final con `test_master` (enfoque purista)\n",
    "\n",
    "En este notebook realizamos la **evaluación final** del modelo de churn valioso usando el conjunto de test que se reservó desde el principio (`test_master.csv`).\n",
    "\n",
    "Pasos generales:\n",
    "\n",
    "1. Cargar `train_master` y `test_master`.\n",
    "2. Replicar la creación de variables del EDA (Recency, MntTotal, CLV, etc.).\n",
    "3. Definir `Churn_Valioso_KMeans` en train y test usando las **mismas reglas**.\n",
    "4. Preparar `X_test` e `y_test`.\n",
    "5. Cargar el modelo `churn_pipeline.pkl` entrenado en el notebook 4.\n",
    "6. Evaluar métricas finales (ROC-AUC, matriz de confusión, recall, F1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb7753",
   "metadata": {},
   "source": [
    "## 1. Carga de `train_master` y `test_master`\n",
    "\n",
    "Cargamos los archivos generados en el notebook 0. `train_master` se usa solo para obtener la mediana de `CLV_log` (para reproducir la definición de valioso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b1ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data\")\n",
    "train = pd.read_csv(data_path / \"train_master.csv\")\n",
    "test = pd.read_csv(data_path / \"test_master.csv\")\n",
    "\n",
    "train.shape, test.shape\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67041bb",
   "metadata": {},
   "source": [
    "## 2. Replicar la ingeniería de variables del EDA\n",
    "\n",
    "Aquí debes replicar la lógica usada en `1_EDA_Superstore.ipynb` para crear:\n",
    "\n",
    "- `MntTotal`\n",
    "- `TotalPurchases`\n",
    "- `Perc_WebPurchases`, `Perc_CatalogPurchases`, `Perc_StorePurchases`\n",
    "- `CLV_simple`\n",
    "- `CLV_log`\n",
    "\n",
    "Las fórmulas dependen de los nombres de columnas de tu dataset original (por ejemplo, sumas de importes por canal y número de compras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"# Ejemplo genérico: ajusta estos nombres según tu dataset real\n",
    "# train[\"MntTotal\"] = train[[\"MntWines\", \"MntFruits\", ...]].sum(axis=1)\n",
    "# test[\"MntTotal\"] = test[[\"MntWines\", \"MntFruits\", ...]].sum(axis=1)\n",
    "\n",
    "# train[\"TotalPurchases\"] = train[[\"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\"]].sum(axis=1)\n",
    "# test[\"TotalPurchases\"] = test[[\"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\"]].sum(axis=1)\n",
    "\n",
    "# train[\"Perc_WebPurchases\"] = train[\"NumWebPurchases\"] / train[\"TotalPurchases\"].replace(0, 1)\n",
    "# test[\"Perc_WebPurchases\"] = test[\"NumWebPurchases\"] / test[\"TotalPurchases\"].replace(0, 1)\n",
    "\n",
    "# train[\"Perc_CatalogPurchases\"] = train[\"NumCatalogPurchases\"] / train[\"TotalPurchases\"].replace(0, 1)\n",
    "# test[\"Perc_CatalogPurchases\"] = test[\"NumCatalogPurchases\"] / test[\"TotalPurchases\"].replace(0, 1)\n",
    "\n",
    "# train[\"Perc_StorePurchases\"] = train[\"NumStorePurchases\"] / train[\"TotalPurchases\"].replace(0, 1)\n",
    "# test[\"Perc_StorePurchases\"] = test[\"NumStorePurchases\"] / test[\"TotalPurchases\"].replace(0, 1)\n",
    "\n",
    "# train[\"CLV_simple\"] = train[\"MntTotal\"] * train[\"TotalPurchases\"]\n",
    "# test[\"CLV_simple\"] = test[\"MntTotal\"] * test[\"TotalPurchases\"]\n",
    "\n",
    "# import numpy as np\n",
    "# train[\"CLV_log\"] = np.log1p(train[\"MntTotal\"]) * np.log1p(train[\"TotalPurchases\"])\n",
    "# test[\"CLV_log\"] = np.log1p(test[\"MntTotal\"]) * np.log1p(test[\"TotalPurchases\"])\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acfcc57",
   "metadata": {},
   "source": [
    "## 3. Definir `Churn_Valioso_KMeans` en train y test\n",
    "\n",
    "Usamos las mismas reglas que en el EDA:\n",
    "\n",
    "- `UMBRAL_RECENCY_KMEANS = 83`.\n",
    "- Mediana de `CLV_log` calculada **solo con train**.\n",
    "\n",
    "Luego definimos:\n",
    "\n",
    "- `Churn_KMeans = 1` si `Recency >= 83`, si no 0.\n",
    "- `Churn_Valioso_KMeans = 1` si (`Recency >= 83` y `CLV_log >= mediana_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"UMBRAL_RECENCY_KMEANS = 83\n",
    "\n",
    "mediana_clv_train = train[\"CLV_log\"].median()\n",
    "\n",
    "for df_tmp in [train, test]:\n",
    "    df_tmp[\"Churn_KMeans\"] = (df_tmp[\"Recency\"] >= UMBRAL_RECENCY_KMEANS).astype(int)\n",
    "    df_tmp[\"Churn_Valioso_KMeans\"] = (\n",
    "        (df_tmp[\"Recency\"] >= UMBRAL_RECENCY_KMEANS)\n",
    "        & (df_tmp[\"CLV_log\"] >= mediana_clv_train)\n",
    "    ).astype(int)\n",
    "\n",
    "test[\"Churn_Valioso_KMeans\"].value_counts(normalize=True).round(4) * 100\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3286f",
   "metadata": {},
   "source": [
    "## 4. Preparar `X_test` e `y_test`\n",
    "\n",
    "Usamos exactamente las mismas columnas de features que en el notebook 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0bcd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"feature_cols = [\n",
    "    \"Recency\", \"MntTotal\", \"TotalPurchases\", \"Income\",\n",
    "    \"Perc_CatalogPurchases\", \"NumWebVisitsMonth\",\n",
    "    \"Kidhome\", \"Teenhome\",\n",
    "    \"Education\", \"Marital_Status\"\n",
    "]\n",
    "target_col = \"Churn_Valioso_KMeans\"\n",
    "\n",
    "X_test = test[feature_cols].copy()\n",
    "y_test = test[target_col].copy()\n",
    "X_test.shape, y_test.shape\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea8d31",
   "metadata": {},
   "source": [
    "## 5. Cargar el modelo entrenado\n",
    "\n",
    "Cargamos el pipeline `churn_pipeline.pkl` guardado en la carpeta `models/` por el notebook 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f552b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "models_path = Path(\"../models\")\n",
    "churn_model = joblib.load(models_path / \"churn_pipeline.pkl\")\n",
    "churn_model\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd5308",
   "metadata": {},
   "source": [
    "## 6. Evaluación final en test\n",
    "\n",
    "Calculamos las métricas en el conjunto de test (`X_test`, `y_test`):\n",
    "\n",
    "- ROC-AUC\n",
    "- Matriz de confusión\n",
    "- Precision, Recall, F1\n",
    "\n",
    "Esto nos da una estimación honesta del rendimiento del modelo en datos nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2896be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "y_test_proba = churn_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = churn_model.predict(X_test)\n",
    "\n",
    "roc_test = roc_auc_score(y_test, y_test_proba)\n",
    "print(f\"ROC-AUC (test): {roc_test:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de confusión (test):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nReporte de clasificación (test):\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb246d",
   "metadata": {},
   "source": [
    "## 7. Conclusiones finales\n",
    "\n",
    "Aquí debes redactar tus conclusiones sobre:\n",
    "\n",
    "- Rendimiento del modelo en test (¿mantiene lo visto en validación?).\n",
    "- Capacidad para detectar churn valioso (Recall de la clase 1).\n",
    "- Posibles mejoras futuras (más features, otros modelos, calibración de probabilidades, etc.).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
