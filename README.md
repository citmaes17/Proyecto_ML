
# ABC Retain Suite ‚Äì ChurnRadar Valioso  
Proyecto de Segmentaci√≥n de Clientes y Churn Valioso (Superstore)

---

## 1. Resumen ejecutivo

Este repositorio contiene un proyecto completo de **Machine Learning aplicado a marketing relacional**, usando un dataset tipo *Superstore / Marketing Campaign*.

El objetivo principal es doble:

1. **Entender el comportamiento de la base de clientes** mediante:
   - EDA,
   - CDA (an√°lisis estad√≠stico),
   - segmentaci√≥n con K-Means.

2. **Clasificar clientes en riesgo de ‚Äúchurn valioso‚Äù**  
   (clientes de alto valor que han dejado de comprar) y exponerlo en una app:

> **ABC Retain Suite ‚Äì M√≥dulo 1: ChurnRadar Valioso**  
> App + servicio de actualizaci√≥n para ayudar a priorizar campa√±as de retenci√≥n.

---

## 2. Objetivos del proyecto

### Objetivo de negocio

- Identificar **qu√© clientes valiosos** est√°n dejando de comprar.
- Entregar **segmentos** de clientes con significado de negocio.
- Generar una **lista priorizada para campa√±as de retenci√≥n**:
  - a qui√©n llamar,
  - a qui√©n enviar email,
  - en qu√© segmento enfocarse primero.

### Objetivo de Data Science

- Construir un pipeline completo:

  1. **0 ‚Äì Split maestro**: separar train/test antes de todo.
  2. **1 ‚Äì EDA**: conocer la base, crear variables.
  3. **2 ‚Äì CDA**: validar con estad√≠stica lo visto en el EDA.
  4. **3 ‚Äì Segmentaci√≥n K-Means**: 4 clusters de comportamiento.
  5. **4 ‚Äì Modelo supervisado de churn valioso**.
  6. **5 ‚Äì Evaluaci√≥n final sobre test_master**.

- Integrar el modelo en una app de **Streamlit** que haga scoring y permita exportar campa√±as.

---

## 3. Stack tecnol√≥gico

- **Python 3.x**
- **Pandas**, **NumPy**
- **Matplotlib**, **Seaborn**
- **Scikit-learn**
- **Joblib**
- **Streamlit**

---

## 4. Estructura del repositorio

```text
Proyecto_ML/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ superstore_data.csv           # Dataset original (crudo)
‚îÇ   ‚îú‚îÄ‚îÄ superstore_modelado.csv       # Dataset modelado
‚îÇ   ‚îú‚îÄ‚îÄ superstore_para_retencion     # Data set para retencion
‚îÇ   ‚îú‚îÄ‚îÄ superstore_master.csv         # Base limpia + features (previa al split)
‚îÇ   ‚îú‚îÄ‚îÄ train_master.csv              # Split de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ test_master.csv               # Split de test final (no tocado hasta el final)
‚îÇ ‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 0_Split_Master_Superstore.ipynb   # Split purista train/test
‚îÇ   ‚îú‚îÄ‚îÄ 1_EDA_Superstore.ipynb            # EDA + creaci√≥n de variables
‚îÇ   ‚îú‚îÄ‚îÄ 2_CDA_Superstore.ipynb            # CDA + definici√≥n de churn valioso
‚îÇ   ‚îú‚îÄ‚îÄ 3_Segmentacion_Clientes.ipynb     # K-Means + interpretaci√≥n de clusters
‚îÇ   ‚îú‚îÄ‚îÄ 4_Modelo_Churn_Valioso.ipynb      # Modelo supervisado + validaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ 5_Evaluacion_TestMaster.ipynb     # Evaluaci√≥n final en test_master
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ data_overview.py              # Clase/funciones para resumen r√°pido de datos
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ churn_pipeline.pkl            # Pipeline de preprocesado + modelo entrenado
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ ABC_Retain_Suite.py   # App de Streamlit (m√≥dulo 1 de la suite)
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îî‚îÄ‚îÄ ABC_Retai_Suite_Tecnico.pdf # Presentaci√≥n t√©cnica del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ ABC_Retai_Suite.pdf         # Presentaci√≥n del negocio
‚îÇ
‚îî‚îÄ‚îÄ README.md                         # Este documento
```

*(Los nombres de algunos ficheros pueden variar ligeramente, pero la idea de estructura es esta.)*

---

## 5. Datos y variables clave

### 5.1 Dataset

- Base de clientes con informaci√≥n de:
  - Fecha de alta,
  - Compras por distintos canales,
  - Importe total gastado,
  - Visitas web,
  - Variables demogr√°ficas b√°sicas (Income, Kidhome, Teenhome, Education, Marital_Status).

### 5.2 Feature engineering principal

En el EDA se construyen variables clave para comportamiento de cliente:

- **Recency**: d√≠as desde la √∫ltima compra.
- **CustomerTenure**: antig√ºedad del cliente (d√≠as desde alta).
- **MntTotal**: gasto total hist√≥rico.
- **TotalPurchases**: n√∫mero total de compras.
- **Perc_WebPurchases**: % de compras por web.
- **Perc_CatalogPurchases**: % de compras por cat√°logo.
- **Perc_StorePurchases**: % de compras en tienda f√≠sica.
- **NumWebVisitsMonth**: visitas web mensuales.
- **CLV_simple** = `MntTotal * TotalPurchases`.
- **CLV_log** = `log1p(MntTotal) * log1p(TotalPurchases)`  
  (m√°s estable, usado para definir valor del cliente y en el CDA,  
  **no se usa como feature en el modelo supervisado**).

### 5.3 Definici√≥n de Churn Valioso K-Means

1. Se aplica **K-Means sobre Recency** para encontrar el cluster m√°s inactivo.
2. El cluster m√°s inactivo tiene media ‚âà **83 d√≠as sin comprar**.
3. Se definen las condiciones:
   - **Inactivo**: `Recency ‚â• 83`.
   - **Valioso**: `CLV_log ‚â• mediana`.
4. Etiquetas:
   - `Churn_Valioso_KMeans = 1` si (Inactivo & Valioso), si no 0.
   - `Churn_KMeans = 1` si `Recency ‚â• 83` (churn simple, solo inactividad).

Resultados globales (en la base original):

- **Churn Valioso K-Means** ‚âà **8.1 %**.
- **Churn simple (K-Means)** ‚âà **16.5 %**.

Se demuestra en el CDA que **Churn Valioso** es mucho m√°s informativo que el churn simple.

---

## 6. Flujo de trabajo y notebooks

### 6.1 `0_Split_Master_Superstore.ipynb`

**Objetivo:**  
Hacer el split **purista** train/test antes de cualquier an√°lisis, para reservar un **test_master** completamente virgen para la evaluaci√≥n final del modelo.

**Pasos principales:**

1. Carga `superstore_master.csv` (base ya limpia y con features b√°sicas).
2. Hace un split estratificado sobre la etiqueta de churn valioso (`Churn_Valioso_KMeans`).
3. Guarda:
   - `train_master.csv`
   - `test_master.csv`  
     en la carpeta `data/`.

---

### 6.2 `1_EDA_Superstore.ipynb`

**Objetivo:**  
Exploraci√≥n inicial de la data de entrenamiento y creaci√≥n de variables.

**Pasos:**

1. Carga `train_master.csv`.
2. Revisi√≥n r√°pida:
   - tama√±os,
   - tipos de variables,
   - nulos,
   - estad√≠sticas descriptivas.
3. Creaci√≥n de variables de comportamiento (si no ven√≠an ya creadas).
4. Visualizaciones:
   - distribuciones de Recency, MntTotal, TotalPurchases, Income, etc.
   - mix de canales,
   - visitas web.
5. Exploraci√≥n inicial de churn simple y churn valioso (sin hacer a√∫n CDA formal).

---

### 6.3 `2_CDA_Superstore.ipynb`

**Objetivo:**  
Validar estad√≠sticamente lo que se vio en el EDA y **definir formalmente el churn valioso**.

**Pasos:**

1. Confirmaci√≥n de la definici√≥n de `Churn_Valioso_KMeans`:
   - K-Means sobre Recency ‚Üí umbral de inactividad ‚âà 83 d√≠as.
   - Combinaci√≥n con CLV_log ‚â• mediana.
2. C√°lculo de tasas:
   - Churn valioso ‚âà 8.1 %,
   - Churn simple ‚âà 16.5 %.
3. **CDA num√©rica (Mann-Whitney)**:
   - Variables analizadas: Recency, MntTotal, TotalPurchases, Income, Perc_CatalogPurchases, NumWebVisitsMonth, Perc_StorePurchases, etc.
   - Se reportan p-values y **rank-biserial**.
   - Se concluye que:
     - Recency tiene efecto enorme (‚âà 0.91),
     - MntTotal, TotalPurchases, Income, Perc_CatalogPurchases son relevantes,
     - NumWebVisitsMonth est√° inversamente asociada.
4. **CDA categ√≥rica (Chi-cuadrado)**:
   - Kidhome, Teenhome con asociaci√≥n significativa con churn valioso.
   - Education, Marital_Status tienen efecto m√°s suave.
5. Conclusiones:
   - Churn valioso **no es aleatorio**.
   - Hay se√±al suficiente para construir un modelo supervisado.

---

### 6.4 `3_Segmentacion_Clientes.ipynb`

**Objetivo:**  
Segmentar clientes en **4 clusters** con K-Means y describirlos en lenguaje de negocio. Cruzar segmentaci√≥n con churn valioso.

**Features para clustering:**

- Recency, CustomerTenure, MntTotal, TotalPurchases, Income,
- Perc_WebPurchases, Perc_CatalogPurchases, Perc_StorePurchases,
- NumWebVisitsMonth,
- Kidhome, Teenhome.

**Pasos:**

1. Imputaci√≥n simple y **escalado est√°ndar** de variables num√©ricas.
2. K-Means con `k = 4` (trade-off entre simplicidad e interpretabilidad).
3. C√°lculo de medias por cluster ‚Üí tabla de perfil.
4. Heatmaps y visualizaciones comparando clusters.
5. **Cruce con Churn_Valioso_KMeans**:
   - Se calculan porcentajes de churn valioso dentro de cada cluster.
   - Se identifican segmentos de alto riesgo vs bajo riesgo.
6. Interpretaci√≥n de negocio:
   - Segmentos con alto valor y alto riesgo,
   - Segmentos de bajo valor casi sin churn valioso,
   - Diferencias por canal y perfil demogr√°fico.

---

### 6.5 `4_Modelo_Churn_Valioso.ipynb`

**Objetivo:**  
Entrenar un modelo supervisado para clasificar **churn valioso** usando solo `train_master.csv` (sin tocar test_master).

**Target:**

- `Churn_Valioso_KMeans`.

**Features usadas:**

- Num√©ricas:
  - Recency, MntTotal, TotalPurchases, Income,
  - Perc_CatalogPurchases, NumWebVisitsMonth,
  - Kidhome, Teenhome.
- Categ√≥ricas:
  - Education, Marital_Status.

> ‚ö†Ô∏è **CLV_log NO se usa como feature**, aunque se us√≥ para definir el churn valioso.  
> Esto evita fuga de informaci√≥n.

**Preprocesamiento y modelo:**

- `ColumnTransformer`:
  - Num√©ricas ‚Üí `SimpleImputer(median)` + `StandardScaler`.
  - Categ√≥ricas ‚Üí `SimpleImputer(most_frequent)` + `OneHotEncoder`.
- `Pipeline` con:
  - `preprocess` + `model`.

**Modelos y tuning:**

- LogisticRegression:
  - Penalty: L1 / L2,
  - C: [0.1, 1.0, 10.0],
  - `class_weight='balanced'`.
- RandomForestClassifier:
  - `n_estimators`: [100, 300],
  - `max_depth`: [None, 5, 10],
  - `min_samples_split`: [2, 5],
  - `class_weight='balanced'`.
- `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`.
- `GridSearchCV` con m√©trica **ROC-AUC**.

**Resultados en validaci√≥n (hold-out):**

- Mejor modelo: **RandomForestClassifier**  
  (`n_estimators=100`, `max_depth=5`, `min_samples_split=2`, `class_weight='balanced'`).
- M√©tricas:
  - ROC-AUC ‚âà **0.9933**.
  - Accuracy ‚âà **0.9955**.
  - Precision (clase 1 ‚Äì churn valioso) ‚âà **0.9722**.
  - Recall (clase 1) ‚âà **0.9722**.
- Importancias:
  - Recency domina,
  - luego MntTotal, TotalPurchases, Income, Perc_CatalogPurchases,
  - y en menor medida Kidhome, NumWebVisitsMonth, Teenhome y algunas categor√≠as.

**Salida:**

- Se guarda el pipeline completo (preprocesado + modelo) en:
  - `models/churn_pipeline.pkl`.

---

### 6.6 `5_Evaluacion_TestMaster.ipynb`

**Objetivo:**  
Hacer la **evaluaci√≥n final** del modelo usando `test_master.csv` (datos nunca vistos).

**Pasos:**

1. Carga `test_master.csv`.
2. Carga el `churn_pipeline.pkl`.
3. Obtiene:
   - Probabilidades de churn valioso.
   - Predicciones finales.
4. Calcula m√©tricas sobre test:
   - ROC-AUC,
   - matriz de confusi√≥n,
   - precision, recall, F1 de la clase positiva.
5. Compara resultados de validaci√≥n vs test para comprobar que no hay sobreajuste grave.
6. Deja listas las columnas necesarias (`Churn_Valioso_Pred`, `Churn_Valioso_Prob`) para que la app las use.

---

## 7. Modelo de churn valioso: resumen

- **Tipo de problema**: clasificaci√≥n binaria (`Churn_Valioso_KMeans` = 1 / 0).
- **Distribuci√≥n** (en train):
  - ‚âà 8% clase positiva (churn valioso),
  - ‚âà 92% clase negativa.
- **Enfoque**:
  - Pipeline con preprocesado separando num√©ricas y categ√≥ricas.
  - Modelos comparados: Logistic Regression vs RandomForest.
  - Selecci√≥n v√≠a GridSearchCV y ROC-AUC.
- **Mejor modelo**:
  - RandomForest con profundidad moderada.
- **Uso en producci√≥n / demo**:
  - El modelo se serializa con Joblib,
  - La app de Streamlit lo usa para hacer scoring.

---

## 8. Segmentaci√≥n K-Means: resumen

- **N√∫mero de clusters**: k = 4.

- **Variables**:
  - Recency, CustomerTenure, MntTotal, TotalPurchases, Income,
  - Perc_WebPurchases, Perc_CatalogPurchases, Perc_StorePurchases,
  - NumWebVisitsMonth, Kidhome, Teenhome.

- **Preprocesamiento**:
  - Imputaci√≥n + StandardScaler.

- **Interpretaci√≥n**:
  - Se obtienen perfiles como:
    - Segmentos de **alto gasto y alta frecuencia** (clientes premium).
    - Segmentos de **bajo gasto y baja frecuencia**.
    - Segmentos m√°s digitales vs m√°s de tienda f√≠sica.
  - Al cruzar con churn valioso:
    - Algunos clusters concentran un % mucho mayor de churn valioso.
    - Otros apenas aportan churn valioso ‚Üí baja prioridad de inversi√≥n.

---

## 9. App: ABC Retain Suite ‚Äì ChurnRadar Valioso

La app est√° en:

```text
app/app_ABC_Retain_Suite_ChurnRadar.py
```

### 9.1 Ejecuci√≥n

Desde la carpeta ra√≠z del proyecto:

```bash
cd Proyecto_ML
streamlit run app/app_ABC_Retain_Suite_ChurnRadar.py
```

Requisitos:

- Tener instalado `streamlit` y las dependencias del proyecto.
- Tener el modelo entrenado en `models/churn_pipeline.pkl`.
- Tener disponible una base con las mismas columnas que `train_master.csv` / `test_master.csv`.

### 9.2 Pesta√±as (seg√∫n dise√±o actual)

La app est√° pensada como el **M√≥dulo 1 de ABC Retain Suite**.

1. **üìä Panel ejecutivo**
   - N√∫mero de clientes.
   - % de churn valioso (hist√≥rico o predicho).
   - Gasto total y CLV medio.
   - Gr√°ficos:
     - Distribuci√≥n por cluster.
     - Churn valioso por cluster (%).

2. **üß© Segmentaci√≥n**
   - Tama√±o de cada cluster.
   - Tabla con medias por cluster.
   - Descripci√≥n de cada segmento en lenguaje de negocio.
   - Filtro para explorar clientes de un cluster concreto.

3. **üî• Churn Valioso**
   - Distribuci√≥n de churn valioso (0/1).
   - Distribuci√≥n por nivel de riesgo (Alto / Medio / Bajo).
   - Si la base tiene etiqueta hist√≥rica, se muestra:
     - matriz de confusi√≥n,
     - classification_report.

4. **üì§ Exportar campa√±as**
   - Filtros:
     - cluster,
     - nivel de riesgo,
     - probabilidad m√≠nima de churn,
     - top-N clientes.
   - Tabla con clientes priorizados.
   - Bot√≥n para descargar CSV listo para activaci√≥n en campa√±as.

---

## 10. C√≥mo reproducir el proyecto

### 10.1 Requisitos

1. Clonar este repositorio.
2. Crear un entorno virtual (opcional pero recomendado):

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scriptsctivate      # Windows
```

3. Instalar dependencias:

```bash
pip install -r requirements.txt
```

*(Si no hay `requirements.txt`, instalar: pandas, numpy, scikit-learn, matplotlib, seaborn, joblib, streamlit.)*

### 10.2 Orden recomendado de ejecuci√≥n

1. Ejecutar `0_Split_Master_Superstore.ipynb`  
   ‚Üí genera `train_master.csv` y `test_master.csv`.

2. Ejecutar `1_EDA_Superstore.ipynb`  
   ‚Üí an√°lisis exploratorio sobre `train_master`.

3. Ejecutar `2_CDA_Superstore.ipynb`  
   ‚Üí definici√≥n y validaci√≥n de `Churn_Valioso_KMeans`.

4. Ejecutar `3_Segmentacion_Clientes.ipynb`  
   ‚Üí K-Means y perfiles de segmentos.

5. Ejecutar `4_Modelo_Churn_Valioso.ipynb`  
   ‚Üí entrenamiento del modelo y guardado de `churn_pipeline.pkl`.

6. Ejecutar `5_Evaluacion_TestMaster.ipynb`  
   ‚Üí evaluaci√≥n final en `test_master`.

7. Lanzar la app de Streamlit:

```bash
streamlit run app/app_ABC_Retain_Suite_ChurnRadar.py
```

---

## 11. Limitaciones y trabajo futuro

- La definici√≥n de **churn valioso** se basa en:
  - Recency ‚â• 83 d√≠as + CLV_log ‚â• mediana.  
  El modelo reproduce muy bien esa definici√≥n, pero:
  - est√° fuertemente anclado a Recency,
  - funciona como excelente **clasificador del estado actual**,
  - no es un modelo de *early warning* puro (a varios meses vista).
- El dataset corresponde a un solo contexto de negocio:
  - la generalizaci√≥n a otros sectores requiere reentrenar el modelo con sus datos.
- Trabajo futuro:
  - redefinir churn con ventanas temporales (30‚Äì60‚Äì90 d√≠as),
  - incorporar m√°s se√±ales temporales y digitales,
  - construir un m√≥dulo espec√≠fico de **recomendaci√≥n (cross-sell / up-sell)**,
  - a√±adir interpretabilidad avanzada (SHAP, etc.) si el contexto lo requiere.

---

## 12. Contacto / cr√©ditos

Este proyecto forma parte de un **proceso formativo y de portfolio en Data Science y Machine Learning aplicado a marketing**, y se integra como el primer m√≥dulo de:

> **ABC Retain Suite** ‚Äì herramientas para cuidar el valor de tus clientes.

```markdown
Autor: [Tu nombre aqu√≠]  
Rol: Data Scientist / Analista de Marketing Data-Driven
```

Puedes adaptar este README para GitHub, para portfolio profesional, para entregas acad√©micas o para presentar el proyecto a equipos de negocio y Data Science.
