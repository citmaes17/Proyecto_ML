
# ABC Retain Suite â€“ ChurnRadar Valioso  
Proyecto de SegmentaciÃ³n de Clientes y Churn Valioso (Superstore)

---

## 1. Resumen ejecutivo

Este repositorio contiene un proyecto completo de **Machine Learning aplicado a marketing relacional**, usando un dataset tipo *Superstore / Marketing Campaign*.

El objetivo principal es doble:

1. **Entender el comportamiento de la base de clientes** mediante:
   - EDA,
   - CDA (anÃ¡lisis estadÃ­stico),
   - segmentaciÃ³n con K-Means.

2. **Clasificar clientes en riesgo de â€œchurn valiosoâ€**  
   (clientes de alto valor que han dejado de comprar) y exponerlo en una app:

> **ABC Retain Suite â€“ MÃ³dulo 1: ChurnRadar Valioso**  
> App + servicio de actualizaciÃ³n para ayudar a priorizar campaÃ±as de retenciÃ³n.

---

## 2. Objetivos del proyecto

### Objetivo de negocio

- Identificar **quÃ© clientes valiosos** estÃ¡n dejando de comprar.
- Entregar **segmentos** de clientes con significado de negocio.
- Generar una **lista priorizada para campaÃ±as de retenciÃ³n**:
  - a quiÃ©n llamar,
  - a quiÃ©n enviar email,
  - en quÃ© segmento enfocarse primero.

### Objetivo de Data Science

- Construir un pipeline completo:

  1. **0 â€“ Split maestro**: separar train/test antes de todo.
  2. **1 â€“ EDA**: conocer la base, crear variables.
  3. **2 â€“ CDA**: validar con estadÃ­stica lo visto en el EDA.
  4. **3 â€“ SegmentaciÃ³n K-Means**: 4 clusters de comportamiento.
  5. **4 â€“ Modelo supervisado de churn valioso**.
  6. **5 â€“ EvaluaciÃ³n final sobre test_master**.

- Integrar el modelo en una app de **Streamlit** que haga scoring y permita exportar campaÃ±as.

---

## 3. Stack tecnolÃ³gico

- **Python 3.x**
- **Pandas**, **NumPy**
- **Matplotlib**, **Seaborn**
- **Scikit-learn**
- **Joblib**
- **Streamlit**

---

## 4. Estructura del repositorio

```text
Proyecto_ML/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ superstore_data.csv           # Dataset original (crudo)
â”‚   â”œâ”€â”€ superstore_modelado.csv       # Dataset modelado
â”‚   â”œâ”€â”€ superstore_para_retencion     # Data set para retencion
â”‚   â”œâ”€â”€ superstore_master.csv         # Base limpia + features (previa al split)
â”‚   â”œâ”€â”€ train_master.csv              # Split de entrenamiento
â”‚   â”œâ”€â”€ test_master.csv               # Split de test final (no tocado hasta el final)
â”‚ â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 0_Split_Master_Superstore.ipynb   # Split purista train/test
â”‚   â”œâ”€â”€ 1_EDA_Superstore.ipynb            # EDA + creaciÃ³n de variables
â”‚   â”œâ”€â”€ 2_CDA_Superstore.ipynb            # CDA + definiciÃ³n de churn valioso
â”‚   â”œâ”€â”€ 3_Segmentacion_Clientes.ipynb     # K-Means + interpretaciÃ³n de clusters
â”‚   â”œâ”€â”€ 4_Modelo_Churn_Valioso.ipynb      # Modelo supervisado + validaciÃ³n
â”‚   â””â”€â”€ 5_Evaluacion_TestMaster.ipynb     # EvaluaciÃ³n final en test_master
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ data_overview.py              # Clase/funciones para resumen rÃ¡pido de datos
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ churn_pipeline.pkl            # Pipeline de preprocesado + modelo entrenado
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ ABC_Retain_Suite.py   # App de Streamlit (mÃ³dulo 1 de la suite)
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ ABC_Retai_Suite_Tecnico.pdf # PresentaciÃ³n tÃ©cnica del proyecto
â”‚   â””â”€â”€ ABC_Retai_Suite.pdf         # PresentaciÃ³n del negocio
â”‚
â””â”€â”€ README.md                         # Este documento
```

*(Los nombres de algunos ficheros pueden variar ligeramente, pero la idea de estructura es esta.)*

---

## 5. Datos y variables clave

### 5.1 Dataset

- Base de clientes con informaciÃ³n de:
  - Fecha de alta,
  - Compras por distintos canales,
  - Importe total gastado,
  - Visitas web,
  - Variables demogrÃ¡ficas bÃ¡sicas (Income, Kidhome, Teenhome, Education, Marital_Status).

### 5.2 Feature engineering principal

En el EDA se construyen variables clave para comportamiento de cliente:

- **Recency**: dÃ­as desde la Ãºltima compra.
- **CustomerTenure**: antigÃ¼edad del cliente (dÃ­as desde alta).
- **MntTotal**: gasto total histÃ³rico.
- **TotalPurchases**: nÃºmero total de compras.
- **Perc_WebPurchases**: % de compras por web.
- **Perc_CatalogPurchases**: % de compras por catÃ¡logo.
- **Perc_StorePurchases**: % de compras en tienda fÃ­sica.
- **NumWebVisitsMonth**: visitas web mensuales.
- **CLV_simple** = `MntTotal * TotalPurchases`.
- **CLV_log** = `log1p(MntTotal) * log1p(TotalPurchases)`  
  (mÃ¡s estable, usado para definir valor del cliente y en el CDA,  
  **no se usa como feature en el modelo supervisado**).

### 5.3 DefiniciÃ³n de Churn Valioso K-Means

1. Se aplica **K-Means sobre Recency** para encontrar el cluster mÃ¡s inactivo.
2. El cluster mÃ¡s inactivo tiene media â‰ˆ **83 dÃ­as sin comprar**.
3. Se definen las condiciones:
   - **Inactivo**: `Recency â‰¥ 83`.
   - **Valioso**: `CLV_log â‰¥ mediana`.
4. Etiquetas:
   - `Churn_Valioso_KMeans = 1` si (Inactivo & Valioso), si no 0.
   - `Churn_KMeans = 1` si `Recency â‰¥ 83` (churn simple, solo inactividad).

Resultados globales (en la base original):

- **Churn Valioso K-Means** â‰ˆ **8.1 %**.
- **Churn simple (K-Means)** â‰ˆ **16.5 %**.

Se demuestra en el CDA que **Churn Valioso** es mucho mÃ¡s informativo que el churn simple.

---

## 6. Flujo de trabajo y notebooks

### 6.1 `0_Split_Master_Superstore.ipynb`

**Objetivo:**  
Hacer el split **purista** train/test antes de cualquier anÃ¡lisis, para reservar un **test_master** completamente virgen para la evaluaciÃ³n final del modelo.

**Pasos principales:**

1. Carga `superstore_master.csv` (base ya limpia y con features bÃ¡sicas).
2. Hace un split estratificado sobre la etiqueta de churn valioso (`Churn_Valioso_KMeans`).
3. Guarda:
   - `train_master.csv`
   - `test_master.csv`  
     en la carpeta `data/`.

---

### 6.2 `1_EDA_Superstore.ipynb`

**Objetivo:**  
ExploraciÃ³n inicial de la data de entrenamiento y creaciÃ³n de variables.

**Pasos:**

1. Carga `train_master.csv`.
2. RevisiÃ³n rÃ¡pida:
   - tamaÃ±os,
   - tipos de variables,
   - nulos,
   - estadÃ­sticas descriptivas.
3. CreaciÃ³n de variables de comportamiento (si no venÃ­an ya creadas).
4. Visualizaciones:
   - distribuciones de Recency, MntTotal, TotalPurchases, Income, etc.
   - mix de canales,
   - visitas web.
5. ExploraciÃ³n inicial de churn simple y churn valioso (sin hacer aÃºn CDA formal).

---

### 6.3 `2_CDA_Superstore.ipynb`

**Objetivo:**  
Validar estadÃ­sticamente lo que se vio en el EDA y **definir formalmente el churn valioso**.

**Pasos:**

1. ConfirmaciÃ³n de la definiciÃ³n de `Churn_Valioso_KMeans`:
   - K-Means sobre Recency â†’ umbral de inactividad â‰ˆ 83 dÃ­as.
   - CombinaciÃ³n con CLV_log â‰¥ mediana.
2. CÃ¡lculo de tasas:
   - Churn valioso â‰ˆ 8.1 %,
   - Churn simple â‰ˆ 16.5 %.
3. **CDA numÃ©rica (Mann-Whitney)**:
   - Variables analizadas: Recency, MntTotal, TotalPurchases, Income, Perc_CatalogPurchases, NumWebVisitsMonth, Perc_StorePurchases, etc.
   - Se reportan p-values y **rank-biserial**.
   - Se concluye que:
     - Recency tiene efecto enorme (â‰ˆ 0.91),
     - MntTotal, TotalPurchases, Income, Perc_CatalogPurchases son relevantes,
     - NumWebVisitsMonth estÃ¡ inversamente asociada.
4. **CDA categÃ³rica (Chi-cuadrado)**:
   - Kidhome, Teenhome con asociaciÃ³n significativa con churn valioso.
   - Education, Marital_Status tienen efecto mÃ¡s suave.
5. Conclusiones:
   - Churn valioso **no es aleatorio**.
   - Hay seÃ±al suficiente para construir un modelo supervisado.

---

### 6.4 `3_Segmentacion_Clientes.ipynb`

**Objetivo:**  
Segmentar clientes en **4 clusters** con K-Means y describirlos en lenguaje de negocio. Cruzar segmentaciÃ³n con churn valioso.

**Features para clustering:**

- Recency, CustomerTenure, MntTotal, TotalPurchases, Income,
- Perc_WebPurchases, Perc_CatalogPurchases, Perc_StorePurchases,
- NumWebVisitsMonth,
- Kidhome, Teenhome.

**Pasos:**

1. ImputaciÃ³n simple y **escalado estÃ¡ndar** de variables numÃ©ricas.
2. K-Means con `k = 4` (trade-off entre simplicidad e interpretabilidad).
3. CÃ¡lculo de medias por cluster â†’ tabla de perfil.
4. Heatmaps y visualizaciones comparando clusters.
5. **Cruce con Churn_Valioso_KMeans**:
   - Se calculan porcentajes de churn valioso dentro de cada cluster.
   - Se identifican segmentos de alto riesgo vs bajo riesgo.
6. InterpretaciÃ³n de negocio:
   - Segmentos con alto valor y alto riesgo,
   - Segmentos de bajo valor casi sin churn valioso,
   - Diferencias por canal y perfil demogrÃ¡fico.

---

### 6.5 `4_Modelo_Churn_Valioso.ipynb`

**Objetivo:**  
Entrenar un modelo supervisado para clasificar **churn valioso** usando solo `train_master.csv` (sin tocar test_master).

**Target:**

- `Churn_Valioso_KMeans`.

**Features usadas:**

- NumÃ©ricas:
  - Recency, MntTotal, TotalPurchases, Income,
  - Perc_CatalogPurchases, NumWebVisitsMonth,
  - Kidhome, Teenhome.
- CategÃ³ricas:
  - Education, Marital_Status.

> âš ï¸ **CLV_log NO se usa como feature**, aunque se usÃ³ para definir el churn valioso.  
> Esto evita fuga de informaciÃ³n.

**Preprocesamiento y modelo:**

- `ColumnTransformer`:
  - NumÃ©ricas â†’ `SimpleImputer(median)` + `StandardScaler`.
  - CategÃ³ricas â†’ `SimpleImputer(most_frequent)` + `OneHotEncoder`.
- `Pipeline` con:
  - `preprocess` + `model`.

**Modelos y tuning:**

- LogisticRegression:
  - Penalty: L1 / L2,
  - C: [0.1, 1.0, 10.0],
  - `class_weight='balanced'`.
- RandomForestClassifier:
  - `n_estimators`: [100, 300],
  - `max_depth`: [None, 5, 10],
  - `min_samples_split`: [2, 5],
  - `class_weight='balanced'`.
- `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`.
- `GridSearchCV` con mÃ©trica **ROC-AUC**.

**Resultados en validaciÃ³n (hold-out):**

- Mejor modelo: **RandomForestClassifier**  
  (`n_estimators=100`, `max_depth=5`, `min_samples_split=2`, `class_weight='balanced'`).
- MÃ©tricas:
  - ROC-AUC â‰ˆ **0.9933**.
  - Accuracy â‰ˆ **0.9955**.
  - Precision (clase 1 â€“ churn valioso) â‰ˆ **0.9722**.
  - Recall (clase 1) â‰ˆ **0.9722**.
- Importancias:
  - Recency domina,
  - luego MntTotal, TotalPurchases, Income, Perc_CatalogPurchases,
  - y en menor medida Kidhome, NumWebVisitsMonth, Teenhome y algunas categorÃ­as.

**Salida:**

- Se guarda el pipeline completo (preprocesado + modelo) en:
  - `models/churn_pipeline.pkl`.

---

### 6.6 `5_Evaluacion_TestMaster.ipynb`

**Objetivo:**  
Hacer la **evaluaciÃ³n final** del modelo usando `test_master.csv` (datos nunca vistos).

**Pasos:**

1. Carga `test_master.csv`.
2. Carga el `churn_pipeline.pkl`.
3. Obtiene:
   - Probabilidades de churn valioso.
   - Predicciones finales.
4. Calcula mÃ©tricas sobre test:
   - ROC-AUC,
   - matriz de confusiÃ³n,
   - precision, recall, F1 de la clase positiva.
5. Compara resultados de validaciÃ³n vs test para comprobar que no hay sobreajuste grave.
6. Deja listas las columnas necesarias (`Churn_Valioso_Pred`, `Churn_Valioso_Prob`) para que la app las use.

---

## 7. Modelo de churn valioso: resumen

- **Tipo de problema**: clasificaciÃ³n binaria (`Churn_Valioso_KMeans` = 1 / 0).
- **DistribuciÃ³n** (en train):
  - â‰ˆ 8% clase positiva (churn valioso),
  - â‰ˆ 92% clase negativa.
- **Enfoque**:
  - Pipeline con preprocesado separando numÃ©ricas y categÃ³ricas.
  - Modelos comparados: Logistic Regression vs RandomForest.
  - SelecciÃ³n vÃ­a GridSearchCV y ROC-AUC.
- **Mejor modelo**:
  - RandomForest con profundidad moderada.
- **Uso en producciÃ³n / demo**:
  - El modelo se serializa con Joblib,
  - La app de Streamlit lo usa para hacer scoring.

---

## 8. SegmentaciÃ³n K-Means: resumen

- **NÃºmero de clusters**: k = 4.

- **Variables**:
  - Recency, CustomerTenure, MntTotal, TotalPurchases, Income,
  - Perc_WebPurchases, Perc_CatalogPurchases, Perc_StorePurchases,
  - NumWebVisitsMonth, Kidhome, Teenhome.

- **Preprocesamiento**:
  - ImputaciÃ³n + StandardScaler.

- **InterpretaciÃ³n**:
  - Se obtienen perfiles como:
    - Segmentos de **alto gasto y alta frecuencia** (clientes premium).
    - Segmentos de **bajo gasto y baja frecuencia**.
    - Segmentos mÃ¡s digitales vs mÃ¡s de tienda fÃ­sica.
  - Al cruzar con churn valioso:
    - Algunos clusters concentran un % mucho mayor de churn valioso.
    - Otros apenas aportan churn valioso â†’ baja prioridad de inversiÃ³n.

---

## 9. App: ABC Retain Suite â€“ ChurnRadar Valioso

La app estÃ¡ en:

```text
app/app_ABC_Retain_Suite_ChurnRadar.py
```

### 9.1 EjecuciÃ³n

Desde la carpeta raÃ­z del proyecto:

```bash
cd Proyecto_ML
streamlit run app/app_ABC_Retain_Suite_ChurnRadar.py
```

Requisitos:

- Tener instalado `streamlit` y las dependencias del proyecto.
- Tener el modelo entrenado en `models/churn_pipeline.pkl`.
- Tener disponible una base con las mismas columnas que `train_master.csv` / `test_master.csv`.

### 9.2 PestaÃ±as (segÃºn diseÃ±o actual)

La app estÃ¡ pensada como el **MÃ³dulo 1 de ABC Retain Suite**.

1. **ðŸ“Š Panel ejecutivo**
   - NÃºmero de clientes.
   - % de churn valioso (histÃ³rico o predicho).
   - Gasto total y CLV medio.
   - GrÃ¡ficos:
     - DistribuciÃ³n por cluster.
     - Churn valioso por cluster (%).

2. **ðŸ§© SegmentaciÃ³n**
   - TamaÃ±o de cada cluster.
   - Tabla con medias por cluster.
   - DescripciÃ³n de cada segmento en lenguaje de negocio.
   - Filtro para explorar clientes de un cluster concreto.

3. **ðŸ”¥ Churn Valioso**
   - DistribuciÃ³n de churn valioso (0/1).
   - DistribuciÃ³n por nivel de riesgo (Alto / Medio / Bajo).
   - Si la base tiene etiqueta histÃ³rica, se muestra:
     - matriz de confusiÃ³n,
     - classification_report.

4. **ðŸ“¤ Exportar campaÃ±as**
   - Filtros:
     - cluster,
     - nivel de riesgo,
     - probabilidad mÃ­nima de churn,
     - top-N clientes.
   - Tabla con clientes priorizados.
   - BotÃ³n para descargar CSV listo para activaciÃ³n en campaÃ±as.

---

## 10. CÃ³mo reproducir el proyecto

### 10.1 Requisitos

1. Clonar este repositorio.
2. Crear un entorno virtual (opcional pero recomendado):

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scriptsctivate      # Windows
```

3. Instalar dependencias:

```bash
pip install -r requirements.txt
```

*(Si no hay `requirements.txt`, instalar: pandas, numpy, scikit-learn, matplotlib, seaborn, joblib, streamlit.)*

### 10.2 Orden recomendado de ejecuciÃ³n

1. Ejecutar `0_Split_Master_Superstore.ipynb`  
   â†’ genera `train_master.csv` y `test_master.csv`.

2. Ejecutar `1_EDA_Superstore.ipynb`  
   â†’ anÃ¡lisis exploratorio sobre `train_master`.

3. Ejecutar `2_CDA_Superstore.ipynb`  
   â†’ definiciÃ³n y validaciÃ³n de `Churn_Valioso_KMeans`.

4. Ejecutar `3_Segmentacion_Clientes.ipynb`  
   â†’ K-Means y perfiles de segmentos.

5. Ejecutar `4_Modelo_Churn_Valioso.ipynb`  
   â†’ entrenamiento del modelo y guardado de `churn_pipeline.pkl`.

6. Ejecutar `5_Evaluacion_TestMaster.ipynb`  
   â†’ evaluaciÃ³n final en `test_master`.

7. Lanzar la app de Streamlit:

```bash
streamlit run app/app_ABC_Retain_Suite_ChurnRadar.py
```

---

## 11. Limitaciones y trabajo futuro

- La definiciÃ³n de **churn valioso** se basa en:
  - Recency â‰¥ 83 dÃ­as + CLV_log â‰¥ mediana.  
  El modelo reproduce muy bien esa definiciÃ³n, pero:
  - estÃ¡ fuertemente anclado a Recency,
  - funciona como excelente **clasificador del estado actual**,
  - no es un modelo de *early warning* puro (a varios meses vista).
- El dataset corresponde a un solo contexto de negocio:
  - la generalizaciÃ³n a otros sectores requiere reentrenar el modelo con sus datos.
- Trabajo futuro:
  - redefinir churn con ventanas temporales (30â€“60â€“90 dÃ­as),
  - incorporar mÃ¡s seÃ±ales temporales y digitales,
  - construir un mÃ³dulo especÃ­fico de **recomendaciÃ³n (cross-sell / up-sell)**,
  - aÃ±adir interpretabilidad avanzada (SHAP, etc.) si el contexto lo requiere.

---

## 12. Contacto / crÃ©ditos

Este proyecto forma parte de un **proceso formativo y de portfolio en Data Science y Machine Learning **, y se integra como el primer mÃ³dulo de:

> **ABC Retain Suite** â€“ herramientas para cuidar el valor de tus clientes.

```markdown
Autor: Cindy Tatiana Marin Espinosa
Rol: Data Scientist / Analista de Marketing Data-Driven
```


